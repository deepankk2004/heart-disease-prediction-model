import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


#load the dataset
data = pd.read_csv("/content/heart disease dataset.csv")
data.shape
  data.dtypes

# Data Preprocessing
data.replace('?', np.nan, inplace=True)
data = data.apply(pd.to_numeric)
data.fillna(data.mean(), inplace=True)
  
# Feature Selection
X = data.drop("target", axis=1)
y = data["target"]
  
# Split Data into Training and Testing Sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
  
# Train a Random Forest Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)
  
# Evaluate the Model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(report)
  
# Sample new data (replace this with your actual data)
new_data = np.array([63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]).reshape(1, -1)

# If you have a pandas DataFrame:
# new_data = pd.DataFrame(data=[[63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]], columns=[:-1])

# Scale the new data using the same StandardScaler used for training
new_data = scaler.transform(new_data)

# Make predictions
predicted = model.predict(new_data)

# Interpret the prediction (0 for no heart disease, 1 for heart disease)
if predicted[0] == 0:
    print("No Heart Disease")
else:
    print("Heart Disease Detected")
my_data = np.array([19, 1, 3, 200, 300, 1, 0, 170, 1, 190, 5, 3, 7]).reshape(1, -1)
my_data = scaler.transform(my_data)  # Scale the new data
predicted = model.predict(my_data)    # Make predictions

if predicted[0] == 0:
    print("No Heart Disease")
else:
    print("Heart Disease Detected")
